{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34aa9b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: best_bal_model.pth\n",
      "Device: cuda\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_test_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDevice: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# 2. DATA PREPARATION\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Transform for input images\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m transform = val_test_transform \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mval_test_transform\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m transforms.Compose([\n\u001b[32m     51\u001b[39m     transforms.Resize(\u001b[32m256\u001b[39m),\n\u001b[32m     52\u001b[39m     transforms.CenterCrop(\u001b[32m224\u001b[39m),\n\u001b[32m     53\u001b[39m     transforms.ToTensor(),\n\u001b[32m     54\u001b[39m     transforms.Normalize(mean=[\u001b[32m0.485\u001b[39m, \u001b[32m0.456\u001b[39m, \u001b[32m0.406\u001b[39m], std=[\u001b[32m0.229\u001b[39m, \u001b[32m0.224\u001b[39m, \u001b[32m0.225\u001b[39m])\n\u001b[32m     55\u001b[39m ])\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Denormalization for visualization\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdenormalize\u001b[39m(tensor):\n",
      "\u001b[31mNameError\u001b[39m: name 'val_test_transform' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Layer-wise Relevance Propagation (LRP) for ResNet18\n",
    "====================================================\n",
    "\n",
    "LRP is a technique that explains neural network predictions by backpropagating\n",
    "\"relevance\" from the output through all layers to the input pixels.\n",
    "\n",
    "Key LRP Rules:\n",
    "- LRP-0: Basic rule, simple redistribution\n",
    "- LRP-epsilon: Adds small epsilon for numerical stability  \n",
    "- LRP-gamma: Emphasizes positive contributions\n",
    "- LRP-alpha-beta: Separates positive/negative contributions (α + β = 1)\n",
    "\n",
    "For this implementation, we use the Captum library which provides robust LRP.\n",
    "\"\"\"\n",
    "\n",
    "best_path = \"best_bal_model.pth\"\n",
    "\n",
    "# Install captum if not available\n",
    "from captum.attr import LRP\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD MODEL\n",
    "# ============================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained model\n",
    "model_lrp = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model_lrp.fc = nn.Linear(model_lrp.fc.in_features, 1)\n",
    "model_lrp.load_state_dict(torch.load(best_path, map_location=device))\n",
    "model_lrp = model_lrp.to(device)\n",
    "model_lrp.eval()\n",
    "\n",
    "print(f\"Model loaded from: {best_path}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. DATA PREPARATION\n",
    "# ============================================================\n",
    "# Transform for input images\n",
    "transform = val_test_transform if val_test_transform else transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Denormalization for visualization\n",
    "def denormalize(tensor):\n",
    "    \"\"\"Convert normalized tensor back to displayable image\"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(tensor.device)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(tensor.device)\n",
    "    tensor = tensor * std + mean\n",
    "    tensor = torch.clamp(tensor, 0, 1)\n",
    "    return tensor\n",
    "\n",
    "# ============================================================\n",
    "# 3. LRP EXPLAINER CLASS\n",
    "# ============================================================\n",
    "class LRPExplainer:\n",
    "    \"\"\"\n",
    "    Layer-wise Relevance Propagation explainer for binary classification.\n",
    "    \n",
    "    LRP redistributes the prediction score backwards through the network\n",
    "    to assign relevance scores to each input pixel.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.lrp = LRP(model)\n",
    "    \n",
    "    def explain(self, input_tensor, target=None):\n",
    "        \"\"\"\n",
    "        Compute LRP attribution for an input image.\n",
    "        \n",
    "        Args:\n",
    "            input_tensor: Normalized input tensor (1, 3, H, W)\n",
    "            target: Target class (0 or 1 for binary). If None, uses predicted class.\n",
    "        \n",
    "        Returns:\n",
    "            attribution: LRP relevance scores (H, W)\n",
    "        \"\"\"\n",
    "        input_tensor = input_tensor.to(self.device)\n",
    "        input_tensor.requires_grad = True\n",
    "        \n",
    "        # Get prediction if target not specified\n",
    "        if target is None:\n",
    "            with torch.no_grad():\n",
    "                output = self.model(input_tensor)\n",
    "                target = (torch.sigmoid(output) >= 0.5).long().item()\n",
    "        \n",
    "        # Compute LRP attribution\n",
    "        # For binary classification with single output, target=0 means the output neuron\n",
    "        attribution = self.lrp.attribute(input_tensor, target=0)\n",
    "        \n",
    "        # Sum across channels and convert to numpy\n",
    "        attr_np = attribution.squeeze().cpu().detach().numpy()\n",
    "        if attr_np.ndim == 3:\n",
    "            attr_np = attr_np.sum(axis=0)  # Sum RGB channels\n",
    "        \n",
    "        return attr_np\n",
    "    \n",
    "    def predict(self, input_tensor):\n",
    "        \"\"\"Get model prediction probability\"\"\"\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_tensor.to(self.device))\n",
    "            prob = torch.sigmoid(output).item()\n",
    "        return prob\n",
    "\n",
    "# ============================================================\n",
    "# 4. VISUALIZATION FUNCTIONS\n",
    "# ============================================================\n",
    "def visualize_lrp(image_path, explainer, transform, class_names, figsize=(15, 4)):\n",
    "    \"\"\"\n",
    "    Visualize LRP explanation for a single image.\n",
    "    \n",
    "    Shows: Original | LRP Heatmap | Positive Relevance | Overlay\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img_pil = Image.open(image_path).convert('RGB')\n",
    "    img_tensor = transform(img_pil).unsqueeze(0)\n",
    "    \n",
    "    # Get prediction\n",
    "    prob = explainer.predict(img_tensor)\n",
    "    pred_class = class_names[1] if prob >= 0.5 else class_names[0]\n",
    "    pred_prob = prob if prob >= 0.5 else 1 - prob\n",
    "    \n",
    "    # Compute LRP attribution\n",
    "    attr = explainer.explain(img_tensor)\n",
    "    \n",
    "    # Prepare original image for display\n",
    "    img_display = denormalize(img_tensor.squeeze()).permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, 4, figsize=figsize)\n",
    "    \n",
    "    # 1. Original image\n",
    "    axes[0].imshow(img_display)\n",
    "    axes[0].set_title(f\"Original\\nPred: {pred_class} ({pred_prob:.1%})\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # 2. LRP Heatmap (full, blue-white-red)\n",
    "    max_abs = np.abs(attr).max() + 1e-10\n",
    "    axes[1].imshow(attr, cmap='bwr', vmin=-max_abs, vmax=max_abs)\n",
    "    axes[1].set_title(\"LRP Attribution\\n(Red→Pneumonia, Blue→Normal)\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # 3. Positive relevance only (regions supporting the prediction)\n",
    "    attr_positive = np.maximum(attr, 0)\n",
    "    axes[2].imshow(attr_positive, cmap='Reds')\n",
    "    axes[2].set_title(\"Positive Relevance\\n(Supporting prediction)\")\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    # 4. Overlay on original\n",
    "    attr_norm = (attr - attr.min()) / (attr.max() - attr.min() + 1e-10)\n",
    "    heatmap = plt.cm.jet(attr_norm)[:, :, :3]\n",
    "    img_uint8 = (img_display * 255).astype(np.uint8)\n",
    "    heatmap_uint8 = (heatmap * 255).astype(np.uint8)\n",
    "    overlay = cv2.addWeighted(img_uint8, 0.6, heatmap_uint8, 0.4, 0)\n",
    "    axes[3].imshow(overlay)\n",
    "    axes[3].set_title(\"LRP Overlay\\n(Important regions)\")\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, attr\n",
    "\n",
    "def plot_lrp_grid(image_paths, explainer, transform, class_names, rows=4, cols=4):\n",
    "    \"\"\"\n",
    "    Plot LRP explanations for multiple images in a grid.\n",
    "    Each row shows: Original | LRP Heatmap | Overlay\n",
    "    \"\"\"\n",
    "    n_images = min(len(image_paths), rows * cols // 3 * 3)  # Ensure divisible by 3\n",
    "    n_rows = (n_images + 2) // 3  # 3 columns per image (orig, heatmap, overlay)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, 3, figsize=(12, 4 * n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(n_rows):\n",
    "        if i >= len(image_paths):\n",
    "            break\n",
    "            \n",
    "        img_path = image_paths[i]\n",
    "        \n",
    "        # Load and process\n",
    "        img_pil = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = transform(img_pil).unsqueeze(0)\n",
    "        \n",
    "        # Prediction\n",
    "        prob = explainer.predict(img_tensor)\n",
    "        pred_class = class_names[1] if prob >= 0.5 else class_names[0]\n",
    "        pred_prob = prob if prob >= 0.5 else 1 - prob\n",
    "        \n",
    "        # LRP attribution\n",
    "        attr = explainer.explain(img_tensor)\n",
    "        \n",
    "        # Display image\n",
    "        img_display = denormalize(img_tensor.squeeze()).permute(1, 2, 0).cpu().numpy()\n",
    "        \n",
    "        # Column 1: Original\n",
    "        axes[i, 0].imshow(img_display)\n",
    "        axes[i, 0].set_title(f\"Original\\n{pred_class} ({pred_prob:.1%})\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Column 2: LRP Heatmap\n",
    "        max_abs = np.abs(attr).max() + 1e-10\n",
    "        axes[i, 1].imshow(attr, cmap='bwr', vmin=-max_abs, vmax=max_abs)\n",
    "        axes[i, 1].set_title(\"LRP Attribution\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Column 3: Overlay\n",
    "        attr_norm = (attr - attr.min()) / (attr.max() - attr.min() + 1e-10)\n",
    "        heatmap = plt.cm.jet(attr_norm)[:, :, :3]\n",
    "        img_uint8 = (img_display * 255).astype(np.uint8)\n",
    "        heatmap_uint8 = (heatmap * 255).astype(np.uint8)\n",
    "        overlay = cv2.addWeighted(img_uint8, 0.6, heatmap_uint8, 0.4, 0)\n",
    "        axes[i, 2].imshow(overlay)\n",
    "        axes[i, 2].set_title(\"Overlay\")\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"LRP Explanations for Pneumonia Classification\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ============================================================\n",
    "# 5. CREATE EXPLAINER AND RUN\n",
    "# ============================================================\n",
    "print(\"\\nInitializing LRP Explainer...\")\n",
    "lrp_explainer = LRPExplainer(model_lrp, device)\n",
    "print(\"LRP Explainer ready!\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. EXPLAIN SAMPLE IMAGES\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LRP EXPLANATION FOR SAMPLE IMAGES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test on a few normal and pneumonia images\n",
    "print(\"\\n--- Normal Samples ---\")\n",
    "if len(normal_pathes) > 0:\n",
    "    fig, attr = visualize_lrp(normal_pathes[0], lrp_explainer, transform, class_names)\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Pneumonia Samples ---\")  \n",
    "if len(pneumonia_pathes) > 0:\n",
    "    fig, attr = visualize_lrp(pneumonia_pathes[0], lrp_explainer, transform, class_names)\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERPRETATION GUIDE:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"• Red regions: Increase Pneumonia prediction (evidence FOR disease)\")\n",
    "print(\"• Blue regions: Decrease Pneumonia prediction (evidence AGAINST disease)\")\n",
    "print(\"• White regions: Neutral, little influence on prediction\")\n",
    "print(\"• Bright regions in overlay: Most important for the model's decision\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c4b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LRP VISUALIZATION FOR MULTIPLE IMAGES\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LRP Explanations - Normal Cases\")\n",
    "print(\"=\"*60)\n",
    "fig = plot_lrp_grid(normal_pathes[:6], lrp_explainer, transform, class_names, rows=6)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LRP Explanations - Pneumonia Cases\")  \n",
    "print(\"=\"*60)\n",
    "fig = plot_lrp_grid(pneumonia_pathes[:6], lrp_explainer, transform, class_names, rows=6)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
